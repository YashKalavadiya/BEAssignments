{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1r_Ov3yDxKm_PFxKsxesYf9jozG5VmLdU","timestamp":1714190864038},{"file_id":"1auHhb1SMbYjbvGwrFGakMg8OB5AkFsV0","timestamp":1714118458166}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["PS: Classification using Deep neural network - Binary classification using Deep Neural Networks Example: Classify movie reviews into positive\" reviews and \"negative\" reviews, just based on the text content of the reviews. Use IMDB dataset"],"metadata":{"id":"UbAbLHSPmu3G"}},{"cell_type":"code","source":["import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras.datasets import imdb\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n","from tensorflow.keras.preprocessing import sequence\n","\n","\n","max_features = 5000  # Number of words to be extracted from 1 particular row while importing the dataset\n","maxlen = 100  # For each sentence in 1 row, consider only 1st 100 common words\n","\n","\n","# (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n"],"metadata":{"id":"BbSae1Jr-O8c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Not yet finalized!"],"metadata":{"id":"KRQHbct12bCd"}},{"cell_type":"code","source":["# Load the IMDB dataset\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n","\n","# Pad sequences to ensure uniform length\n","x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n","x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n","\n","# Build the model\n","model = Sequential()\n","model.add(Embedding(max_features, 128, input_length=maxlen))\n","model.add(SpatialDropout1D(0.2))\n","model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n","model.add(Dense(16, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=0.5)\n","\n","# Evaluate the model\n","score, acc = model.evaluate(x_test, y_test)\n","print('Test loss:', score)\n","print('Test accuracy:', acc)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"pI4wSYTVxNRF","executionInfo":{"status":"error","timestamp":1714159171195,"user_tz":-330,"elapsed":287879,"user":{"displayName":"Srushti Sonavane","userId":"12690477687957494306"}},"outputId":"b4e32a68-ebdf-4651-8d22-dc274890905f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","782/782 [==============================] - ETA: 0s - loss: 0.4433 - accuracy: 0.7899"]},{"output_type":"error","ename":"IndexError","evalue":"tuple index out of range","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-e972fd102711>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    960\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2_behavior\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: tuple index out of range"]}]},{"cell_type":"code","source":["# Pad sequences to ensure uniform length\n","x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n","x_test = sequence.pad_sequences(x_test, maxlen=maxlen)"],"metadata":{"id":"ghe9Kq4_-P5o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","model.add(Embedding(max_features, 128, input_length=maxlen))\n","model.add(SpatialDropout1D(0.2)) #remove this if you feel\n","model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n","model.add(Dense(1, activation='sigmoid'))"],"metadata":{"id":"X2Ig6V5sUxGa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=0.5)\n","\n","# Evaluate the model\n","m_loss, acc = model.evaluate(x_test, y_test)\n","print('Test loss:', m_loss)\n","print('Test accuracy:', acc)"],"metadata":{"id":"yo5K-WPQkt3R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model1 = Sequential()\n","model1.add(Embedding(max_features, 128, input_length=maxlen))\n","model1.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n","model1.add(Dense(1, activation='sigmoid'))"],"metadata":{"id":"icsebNiZkTHe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Train the model\n","model1.fit(x_train, y_train, batch_size=128, epochs=5, validation_data=0.5)\n","\n","# Evaluate the model\n","m_loss, acc = model1.evaluate(x_test, y_test)\n","print('Test loss:', m_loss)\n","print('Test accuracy:', acc)"],"metadata":{"id":"U_ZYgj35kQeD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.layers import Dense, Embedding, Flatten"],"metadata":{"id":"cxGG-YKglQeb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Build the neural network model\n","model2 = Sequential([\n","    Embedding(input_dim=max_features, output_dim=32, input_length=maxlen),\n","    Flatten(),\n","    Dense(16, activation='relu'),\n","    Dense(1, activation='sigmoid')\n","])\n"],"metadata":{"id":"2R8PPOV2lJFm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","history = model2.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.5)"],"metadata":{"id":"-lLQXfLElRbF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the model\n","test_loss, test_accuracy = model2.evaluate(x_test, y_test)\n","print(\"Test Loss:\", test_loss)\n","print(\"Test Accuracy:\", test_accuracy)\n"],"metadata":{"id":"HJczgRztlWqU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kBADoAFSljMD"},"execution_count":null,"outputs":[]}]}