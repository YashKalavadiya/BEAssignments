start-dfs.sh
start-yarn.sh

hdfs dfs -ls / 
hdfs dfs -mkdir /user
hdfs dfs -mkdir /user/current_user_name
#current_user_name = username you see on terminal like pict or hadoop or exam1

hdfs dfs -mkdir /data

vim test.txt (enter data in file)
hdfs dfs -put ./test.txt /data


#to get map reduce path you can check history py pressing arrow after writing following
yarn jar 
# path_to_hadoop_folder/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.5.jar

syntax:
yarn jar map_reduce_path /data/test.txt /output_folder_which_does'nt_exist

hdfs dbs -ls /
hdfs dfs -ls /output_path
hdfs dfs -cat /output_path/part-r-0000

DONE!!!
